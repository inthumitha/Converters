{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI PHASE II.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN_ihPGR0tYW",
        "outputId": "7295b8e0-d503-4ec3-cd44-7a1bf67435e8"
      },
      "source": [
        " #@title CHAT WITH ME\n",
        "print(\"********* WELCOME TO CHAT WITH ME *********\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* WELCOME TO CHAT WITH ME *********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFA2hQ1c7-Vo",
        "outputId": "488ad84c-8a80-4337-dbb9-dd1671b46518"
      },
      "source": [
        "#@title MOUNT DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtZ_omCe9Ul2",
        "outputId": "faa302f4-142d-431f-ec20-c3e491a658f6"
      },
      "source": [
        "#@title VIDEO TO TEXT\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "if not exists('deepspeech-0.6.1-models'):\n",
        "  !apt-get install -qq sox\n",
        "  !pip install -q deepspeech-gpu==0.6.1 youtube-dl\n",
        "  !wget https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz\n",
        "  !tar xvfz deepspeech-0.6.1-models.tar.gz\n",
        "  \n",
        "from IPython.display import YouTubeVideo\n",
        "#YOUTUBE_ID = '2AFpAATHXtc'  \n",
        "YOUTUBE_ID = '4FDud9Lj5HY'\n",
        "YouTubeVideo(YOUTUBE_ID)\n",
        "!rm -rf *.wav\n",
        "!youtube-dl --extract-audio --audio-format wav --output \"test.%(ext)s\" https://www.youtube.com/watch\\?v\\={YOUTUBE_ID}\n",
        "!deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --lm deepspeech-0.6.1-models/lm.binary --trie deepspeech-0.6.1-models/trie --audio test.wav"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] 4FDud9Lj5HY: Downloading webpage\n",
            "[download] Destination: test.webm\n",
            "\u001b[K[download] 100% of 1.18MiB in 00:21\n",
            "[ffmpeg] Destination: test.wav\n",
            "Deleting original file test.webm (pass -k to keep)\n",
            "Loading model from file deepspeech-0.6.1-models/output_graph.pbmm\n",
            "TensorFlow: v1.14.0-21-ge77504a\n",
            "DeepSpeech: v0.6.1-0-g3df20fe\n",
            "2022-06-21 04:41:57.718460: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-06-21 04:41:57.719635: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2022-06-21 04:41:57.727602: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-06-21 04:41:57.727658: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (2e3c122107b8): /proc/driver/nvidia/version does not exist\n",
            "Loaded model in 0.0181s.\n",
            "Loading language model from files deepspeech-0.6.1-models/lm.binary deepspeech-0.6.1-models/trie\n",
            "Loaded language model in 0.000251s.\n",
            "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
            "Running inference.\n",
            "oh if you want something you've never had before you must do something you've never done before it taking me hear of tragedy of losing mineself inside only to realize what i must have always known that you can be anything you dream dream dream into your dream come true after honour passion and when your shot come take in and look fear in the face and imprinting is now the moon is now in yourself like denote the old\n",
            "Inference took 53.221s for 221.503s audio file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY1gFG_m9cfi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "984cfc41-d533-458e-fb5a-0c355bd3ca28"
      },
      "source": [
        "#@title IMAGE TO TEXT\n",
        "import cv2\n",
        "# !pip install pytesseract\n",
        "# !pip install Pillow \n",
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev\n",
        "! pip install Pillow\n",
        "! pip install pytesseract\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import pytesseract \n",
        "from IPython.display import display # to display images\n",
        "pytesseract.pytesseract.tesseract_cmd = (r'/usr/bin/tesseract')\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "image=Image.open('/content/drive/MyDrive/123.png','r')\n",
        "display(image)\n",
        "text = pytesseract.image_to_string(image)\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libtesseract-dev is already the newest version (4.00~git2288-10f4998a-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (9.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.9)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (9.1.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a3511ce4f19a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#uploaded = files.upload()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/123.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3068\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3069\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/123.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OX-knjFpUdX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLjfKDJt-DYa"
      },
      "source": [
        "#@title SENTIMENT ANALYZER\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "!pip install -U nltk\n",
        "sns.set(rc={'figure.figsize':(30,1)})\n",
        "\n",
        "def visualise_sentiments(data):\n",
        "  sns.heatmap(pd.DataFrame(data).set_index(\"Sentence\").T,center=0, annot=True, cmap = \"PiYG\")\n",
        "sentence =input()\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "sid.polarity_scores(sentence)\n",
        "visualise_sentiments({\n",
        "    \"Sentence\":[\"SENTENCE\"] + sentence.split(),\n",
        "    \"Sentiment\":[sid.polarity_scores(sentence)[\"compound\"]] + [sid.polarity_scores(word)[\"compound\"] for word in sentence.split()]\n",
        "})\n",
        "from textblob import TextBlob\n",
        "TextBlob(sentence).sentiment\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBeuqBcH-cl4"
      },
      "source": [
        "#@title CHAT WITH ME\n",
        "import nltk\n",
        "import numpy as np\n",
        "import random\n",
        "import string # to process standard python strings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "\n",
        "f=open('/content/drive/My Drive/ai.txt','r',errors = 'ignore')\n",
        "raw=f.read()\n",
        "raw=raw.lower()# converts to lowercase\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt') # first-time use only\n",
        "nltk.download('wordnet') # first-time use only\n",
        "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
        "word_tokens = nltk.word_tokenize(raw)# converts to list of words\n",
        "\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
        "\n",
        "\n",
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",\"hai\")\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greeting(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)\n",
        "        \n",
        "   \n",
        "GREETING_EXCUSES = [\"Come again please\", \"I can't understand you\", \"Please say one more time\", \"Pardon\", \"I don't know what you are saying\"]\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+random.choice(GREETING_EXCUSES)\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response\n",
        "\n",
        "\n",
        "GREETING_ENDSTATEMENTS= (\"Chat With Me: Bye! take care..\", \"Chat With Me: Bye! I hope to see you soon\", \"Chat With Me: Bye! stay home stay safe\",\"Be safe, See you soon\")\n",
        "GREETING_THANKRESPONSE= (\"Chat With Me: You are welcome\", \"Chat With Me: No mention\", \"Chat With Me: Thanks is banned here\", \"Chat With Me: Don't thank a friend buddy\",\"Chat With Me: Keep it yourself\")\n",
        "\n",
        "flag=True\n",
        "print(\"Chat With Me: My name is Chat With Me. I will answer your queries about Artificial intelligence. If you want to exit, type Bye!\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            thankresponse=random.choice(GREETING_THANKRESPONSE)\n",
        "            print(thankresponse)\n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"Chat With Me: \"+greeting(user_response))\n",
        "            else:\n",
        "                print(\"Chat With Me: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        endstatements=random.choice(GREETING_ENDSTATEMENTS)\n",
        "        print(endstatements)    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}